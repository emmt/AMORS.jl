const default_Î±tol = 0.3
const default_xtol = 1e-4
const default_maxiter = 1000

"""
    AMORS.solve(f, x0, y0) -> (status, x, y)

Apply AMORS strategy out-of-place, that is leaving the intial variables `x0` and `y0`
unchanged. See [`AMORS.solve!`](@ref) for a description of the method.

Methods `Base.similar` and `Base.copyto!` must be applicable to objects of same types as
`x0` and `y0`.

"""
solve(f, x0, y0; kwds...) = solve!(f, copy_variables(x0), copy_variables(y0); kwds...)

# This method only requires that `Base.copyto!` and `Base.similar` be applicable to the
# variables of the problem.
copy_variables(x) = copyto!(similar(x), x)

"""
    AMORS.solve!(f, x, y) -> status, x, y

Estimnate the components of a *bilinear model* by the AMORS method. The argument `f`
represents the objective function (see below). On entry, arguments `x` and `y` are the
initial variables of the problem, they are overwritten by the solution. The result is a
3-tuple with the updated variables and `status` indicating the reason of the algorithm
termination: `status = :convergence` if algorithm has converged in the variables `x` and
`y` within the given tolerances or `status = :too_many_iterations` if the algorithm
exceeded the maximum number of iterations.

The objective of AMORS is to minimize in `x âˆˆ ð•` and `y âˆˆ ð•` an objective function of the
form:

    F(x,y) = G(xâŠ—y) + J(x) + K(y)

where `G` is a function of the *bilinear model* `xâŠ—y`, `J` and `K` are positive
homogeneous functions of the respective variables `x` and `y`. The notation `xâŠ—y` denotes
a *bilinear model* which has the following invariance property:

    (Î±*x)âŠ—(y/Î±) = xâŠ—y

for any scalar factor `Î± > 0`. An *homogeneous function*, say `J: ð• â†’ â„`, of degree `q` is
such that `J(Î±*x) = abs(Î±)^q*J(x)` for any `Î± âˆˆ â„` and for any `x âˆˆ ð•` with `ð•` the domain
of `J`. It can be noted that the following property must hold `âˆ€ Î± âˆˆ â„`: `x âˆˆ ð•` implies
that `Î±*x âˆˆ ð•`. In other words, `ð•` must be a cone.

The argument `f` collects any data, workspaces, parameters, etc. needed to deal with the
objective function `F(x,y)`. This includes `ð•`, `ð•`, `G`, `J`, and `K`. The argument `f`
must be a callable object which is called as:

    f(task, x, y)

where `task` is `Val(:x)` or `Val(:y)` to update this component:

    f(Val(:x), x, y) -> argmin_{x âˆˆ ð•} F(x, y) = argmin_{x âˆˆ ð•} G(xâŠ—y) + J(x)
    f(Val(:y), x, y) -> argmin_{y âˆˆ ð•} F(x, y) = argmin_{y âˆˆ ð•} G(xâŠ—y) + K(y)

while `task` is `Val(:alpha)` to yield the optimal scaling `Î± > 0`:

    f(Val(:alpha), x, y) -> argmin_{Î± > 0} F(Î±*x, y/Î±) = argmin_{Î± > 0} J(Î±*x) + K(y/Î±)

The solution of `argmin_{x âˆˆ ð•} F(x, y)` and `argmin_{y âˆˆ ð•} F(x, y)` may not be exact and
may be computed in-place to save storage, that is `x` (resp. `y`) being overwritten by the
solution. For type stability of the algorithm, `f(Val(:x),x,y)::typeof(x)` and
`f(Val(:y),x,y)::typeof(y)` must hold.

The solution of `argmin_{Î± > 0} F(Î±*x, y/Î±)` has a closed-form expression:

    argmin_{Î± > 0} F(Î±*x, y/Î±) = ((deg(K)*K(y))/(deg(J)*J(x)))^(inv(deg(J) + deg(K)))

where `deg(J)` denotes the degree of the homogeneous function `J`. This solution can be
computed by calling [`AMORS.best_scaling_factor`](@ref).

Arguments `x` and `y` are needed to define the variables. Initially, they must be such
that `J(x) > 0` and `K(y) > 0` unless automatic best rescaling is disabled by
`autoscale = false` (which is not recommended).

The following keywords can be specified:

- `first` is one of `Val(:x)` or `Val(:y)` (the default) to specify which component to
  update the first given the other.

- `Î±tol âˆˆ [0,1)` is a relative tolerance (`$default_Î±tol` by default) to assert the
  convergence in the factor `Î±`.

- `xtol âˆˆ [0,1)` is a relative tolerance (`$default_xtol` by default) to assert the
  convergence in the variables `x`.

- `ytol âˆˆ [0,1)` is a relative tolerance (`xtol` by default) to assert the convergence in
  the variables `y`.

- `maxiter` is the maximum number of algorithm iterations (`$default_maxiter` by default).

- `has_converged` is a function used to check for convergence of the iterates
  ([`AMORS.has_converged`](@ref) by default).

- `autoscale` specifies whether to automatically set the scaling factor `Î±`. By default,
  `autoscale = true`. This keyword is provided for testing the efficiency of the `AMORS`
  algorithm, it is recommended to not disable autoscaling.

"""
function solve!(f, x, y;
                first::Val = Val(:y),
                Î±tol::Real = default_Î±tol,
                xtol::Real = default_xtol,
                ytol::Real = xtol,
                maxiter::Integer = default_maxiter,
                has_converged = AMORS.has_converged,
                observer = nothing,
                autoscale::Bool = true)
    # Check keywords.
    first âˆˆ (Val(:x), Val(:y)) || throw(ArgumentError("bad value for keyword `first`, must be `Val(:x)` or `Val(:y)`"))
    zero(Î±tol) â‰¤ Î±tol < one(Î±tol) || throw(ArgumentError("value of keyword `Î±tol` must be in `[0,1)`"))
    zero(xtol) â‰¤ xtol < one(xtol) || throw(ArgumentError("value of keyword `xtol` must be in `[0,1)`"))
    zero(ytol) â‰¤ ytol < one(ytol) || throw(ArgumentError("value of keyword `ytol` must be in `[0,1)`"))
    maxiter â‰¥ 0 || throw(ArgumentError("value of keyword `maxiter` must be nonnegative"))

    # Initialize algorithm.
    iter = 0
    xp = similar(x)
    yp = similar(y)
    status = :searching
    while true
        # Inspect iterate if requested.
        observer === nothing || observer(iter, f, x, y)

        # Check for convergence.
        if iter > 1 && has_converged(x, xp, xtol) && has_converged(y, yp, ytol)
            status = :convergence # convergence in the variables
            break
        elseif iter â‰¥ maxiter
            status = :too_many_iterations # too many iterations
            break
        end

        # Memorize the components of the problem before updating.
        copyto!(xp, x)
        copyto!(yp, y)

        # Update first component and re-scale. If this is the initial iteration, repeat
        # until convergence in the scaling factor.
        while true
            if first === Val(:x)
                x = f(Val(:x), x, y)::typeof(x)
            else
                y = f(Val(:y), x, y)::typeof(y)
            end
            autoscale || break
            Î± = apply_scaling_factor!(f(Val(:alpha), x, y), x, y)
            if iter â‰¥ 1 || abs(Î± - one(Î±)) â‰¤ Î±tol
                break
            end
        end

        # Update second component and re-scale.
        if first === Val(:x)
            y = f(Val(:y), x, y)::typeof(y)
        else
            x = f(Val(:x), x, y)::typeof(x)
        end
        autoscale && apply_scaling_factor!(f(Val(:alpha), x, y), x, y)

        # Iteration completed.
        iter += 1
    end
    return status, x, y
end

"""
    AMORS.has_converged(x, xp, tol) -> bool

yields whether the variables `x` has converged. Argument `xp` is the previous value of `x`
and `tol â‰¥ 0` is a relative tolerance.

In the default implementation provided by `AMORS` for `x` and `xp` being arrays, the
result is given by:

    â€–x - xpâ€– â‰¤ tolâ‹…â€–xâ€–

with `â€–xâ€–` the Euclidean norm of `x`.

The method is expected to be extended for non-array types of `x` and `xp`. Another
possibility is to specify the keyword `has_converged` in the call to [`AMORS.solve`](@ref)
or [`AMORS.solve!`](@ref).

"""
function has_converged(x::AbstractArray, xp::AbstractArray, tol::Real)
    axes(x) == axes(xp) || throw(DimensionMismatch("arrays must have the same axes"))
    s = abs2(zero(eltype(x)))
    d = abs2(zero(eltype(x)) - zero(eltype(xp)))
    @inbounds @simd for i in eachindex(x, xp)
        s += abs2(x[i])
        d += abs2(x[i] - xp[i])
    end
    return sqrt(d) â‰¤ tol*sqrt(s)
end

"""
    AMORS.scale!(x, Î±::Real) -> x
    AMORS.scale!(Î±::Real, x) -> x

Multiply in-place the entries of `x` by the scalar `Î±` and return `x`. Whatever the values
of the entries of `x`, nothing is done if `Î± = 1` and `x` is zero-filled if `Î± = 0`.

The `AMORS` package provides a default implementation of the method that is applicable to
any abstract array `x`. The method is expected to be extended for other types of argument
`x`.

See also `LinearAlgebra.lmul!(Î±::Number,x::AbstractArray)` and
`LinearAlgebra.rmul!(x::AbstractArray,Î±::Number)`.

"""
scale!(x::AbstractArray, Î±::Number) = scale!(Î±, x)
function scale!(Î±::Number, x::AbstractArray)
    if iszero(Î±)
        fill!(x, zero(eltype(x)))
    else !isone(Î±)
        Î± = convert_floating_point_type(eltype(x), Î±)
        @inbounds @simd for i in eachindex(x)
            x[i] *= Î±
        end
    end
    return x
end

"""
    AMORS.apply_scaling_factor!(Î±::Real, x, y) -> Î±

Multiply in-place the entries of `x` by the scalar `Î±` and the entries of `y` by `inv(Î±)`.
Return `Î±`. See [`AMORS.scale!`](@ref).

"""
function apply_scaling_factor!(Î±::Real, x, y)
    if !isone(Î±)
        scale!(Î±, x)
        scale!(inv(Î±), y)
    end
    return Î±
end

"""
    AMORS.best_scaling_factor(J(x), deg(J), K(y), deg(K)) -> Î±âº

yields the best scaling factor defined by:

    Î±âº = argmin_{Î± > 0} J(Î±*x) + K(y/Î±)

and which has a closed-form expression:

    Î±âº = ((deg(K)*K(y))/(deg(J)*J(x)))^(1/(deg(J) + deg(K)))

The arguments are the values of the homogeneous objective functions, `J(x)` and `K(y)`,
and their respective degrees `deg(J)` and `deg(K)` for the current estimates of the
variables `x` and `y` of a bilinear model.

"""
function best_scaling_factor(Jx::Number, degJ::Number, Ky::Number, degK::Number)
    Jx > zero(Jx) || throw(DomainError(Jx, "`J(x) > 0` must hold"))
    Ky > zero(Ky) || throw(DomainError(Ky, "`K(y) > 0` must hold"))
    degJ > zero(degJ) || throw(DomainError(degJ, "`deg(J) > 0` must hold"))
    degK > zero(degK) || throw(DomainError(degK, "`deg(K) > 0` must hold"))
    return ((degK*Ky)/(degJ*Jx))^inv(degJ + degK)
end
